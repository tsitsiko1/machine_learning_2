{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "practice_proposal.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acastellanos-ie/machine_learning_2/blob/master/naive_bayes_practice/practice_proposal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coUhsrt20sOI"
      },
      "source": [
        "# Google Colab Configuration\n",
        "\n",
        "**Execute this steps to configure the Google Colab environment in order to execute this notebook. It is not required if you are executing it locally and you have properly configured your local environment according to what explained in the Github Repository.**\n",
        "\n",
        "The first step is to clone the repository to have access to all the data and files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ecQfLVZGvm"
      },
      "source": [
        "repository_url = 'https://github.com/acastellanos-ie/machine_learning_2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMgL9W4-0wXE"
      },
      "source": [
        "! git clone $repository_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gAhosq70ypp"
      },
      "source": [
        "Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy8O4JuL00hJ"
      },
      "source": [
        "! pip install -Uqqr machine_learning_2/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6rPx_b2c43D"
      },
      "source": [
        "Go to the practice directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPNxL2Vsch3w"
      },
      "source": [
        "%cd machine_learning_2/naive_bayes_practice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqBBIxf03lS"
      },
      "source": [
        "Ensure that you have the GPU runtime activated:\n",
        "\n",
        "![](https://miro.medium.com/max/3006/1*vOkqNhJNl1204kOhqq59zA.png)\n",
        "\n",
        "Now you have everything you need to execute the code in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l05n5DfhUPWk"
      },
      "source": [
        "The following code includes some imports and configuration steps for better visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj-rVLo9Te7t",
        "outputId": "d9801638-7b40-4bab-dfae-e605514ad620"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # Increase cell width\n",
        "display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\")) # Increase font size\n",
        "\n",
        "# Larger figures\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Do not print warning messages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>.rendered_html { font-size: 16px; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7zFKDpvWBiM"
      },
      "source": [
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUL44FlYWBiO"
      },
      "source": [
        "# Introduction\n",
        "Welcome to the first application of Probabilistic classification with Naïve Bayes!\n",
        "\n",
        "<html>\n",
        "<img src=\"https://www.sketchappsources.com/resources/source-image/twitterlogo_1x.png\" width=\"20%\">\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCWIsY7WBiW"
      },
      "source": [
        "# Exercise #1 (FUNDAMENTAL)\n",
        "In this example we will use **Twitter** as our data source to filter those tweets that are talking about a given application. This is a typical problem in probabilistic classification, where I'll use a large sample of texts corresponding to the category that I want to recognize, and another large sample of texts unrelated to that category. That way, by exploring the different word frequencies and probabilities, we'll determine if a new text belongs to one or another category, by simply looking at the existing evidence.\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "There is a real app called \"Mandrill\"\n",
        "\n",
        "<html>\n",
        "<img src=\"https://pbs.twimg.com/profile_images/604326524976680960/V0gyyhdH.png\" width=\"15%\"><p>\n",
        "</html>\n",
        "\n",
        "And I want to scan twitter to capture only those tweets that mention my APP. But I don't want to read tweets talking about the animal (the actual mandrill), so I need a classifier for the tweets, that will **filter** only those which are relevant.\n",
        "\n",
        "For this part of the problem part of the data preparation job is already done, so you start with a few hundreds tweets captured using Twitter API, with the word **Mandrill** in them. The file with tweets (`appWords.txt`) referring to the app looks like this:\n",
        "\n",
        "    @ericcandino they're unfortunately not for sale but drop us a line via http://help.mandrill.com  a\n",
        "    @gidogeek you can see what we've been working on and get a general idea of our plans at http://blo\n",
        "    @guillaumepotier there are several reasons emails go to spam mind submitting a request at http://h\n",
        "    @icntmx yep  we'd be glad to would you mind submitting a request at http://help.mandrill.com\n",
        "    @jeremyweir if you submit a request at http://help.mandrill.com   we'll get back to you with some\n",
        "    @josscrowcroft mind submitting a request via http://help.mandrill.com  with some additional detail\n",
        "\n",
        "And the file with tweets (`otherWords.txt`) not talking about the app look like this:\n",
        "\n",
        "    anyway  yeah  that's a thing that's going on  reincarnated mandrill-men\n",
        "    arin did the spark mandrill trick i was wondering if he would :')\n",
        "    audio mandrill - happy beat this is a funk song by a band who liked to w\n",
        "    cannot believe i am the only one in a @mandrill 2012 #tweetfleet t-shirt\n",
        "    chill penguin and spark mandrill down #megamanx\n",
        "    cuando pase el bafici y se hayan perdido mandrill  mirageman  mujer metr\n",
        "    de los creadores de #kiltro #mirageman y #mandrill ahora atacan con #trá\n",
        "\n",
        "I trimmed lines for better representation, but they're arbitrarily long (within twitter limits).\n",
        "\n",
        "As you might probably have realized, this is a **supervised problem**, and the _labeling_ of the training data has been already done, by manually separating the tweets among the two possible sets. That is the most boring part, and you always need to do so to train any classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDDFlJ5xWBic"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "What I did to prepare the problem is to process the tweets to convert _raw_ two data files with the frequency count for each individual word on them. So, from `appWords.txt`, I generated `appFreqs.csv`, which summary is like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdUg53RGWBif"
      },
      "source": [
        "appFile = pd.read_csv(\"data/appFreqs.csv\", header=None, names=[\"word\", \"frequency\"])\n",
        "otherFile = pd.read_csv(\"data/otherFreqs.csv\", header=None, names=[\"word\", \"frequency\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHcTVKaiWBig",
        "outputId": "28cda6db-aba7-465a-a40d-1beb8d8f19d6"
      },
      "source": [
        "appFile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#atl</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#atlanta</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#bjcbranding</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#buddypress</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#career</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>852</th>\n",
              "      <td>–</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>‘migrate’</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>“mandrill”</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>…</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>🌿</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>857 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             word  frequency\n",
              "0            #atl         30\n",
              "1        #atlanta         30\n",
              "2    #bjcbranding         30\n",
              "3     #buddypress         30\n",
              "4         #career         30\n",
              "..            ...        ...\n",
              "852             –         90\n",
              "853     ‘migrate’         30\n",
              "854    “mandrill”         30\n",
              "855             …        540\n",
              "856             🌿         30\n",
              "\n",
              "[857 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akkqts2AWBig"
      },
      "source": [
        "These files contains a list of words and their frequency. We need to compute the probabilities from these frequencies (i.e., number of times a word appears w.r.t. the total count of words).\n",
        "\n",
        "To that end, I did simply count the number of occurrences of each word (`frequency`), divided by the sum of occurrences of all the words, and put that in the column variable `probability`, but I also computed the $log$ of the probability. Remember the we can use the actual probability as:\n",
        "\n",
        "$$ P(word) = \\frac{count(word)}{\\sum_{i=1}^{N}count(word_{i})} $$\n",
        "\n",
        "or the $log(P)$, as it is more convenient to use those values than the tiny ones that the probability produces. Remember that when using $logs$ we must sum them, instead of multiplying them. So, what we have in the variable `probability` is:\n",
        "\n",
        "$$ logP(word) = log \\left( \\frac{count(word)}{\\sum_{i=1}^{N}count(word_{i})} \\right)  $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSoOUEwyWBih"
      },
      "source": [
        "appTotal = sum(appFile.frequency)\n",
        "otherTotal = sum(otherFile.frequency)\n",
        "\n",
        "appFile['probability'] = appFile.frequency.apply(lambda x: math.log(x/appTotal))\n",
        "otherFile['probability'] = otherFile.frequency.apply(lambda x: math.log(x/otherTotal))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgoBbIDMWBii",
        "outputId": "f4e1c9b1-4673-4910-bd39-1e916263246f"
      },
      "source": [
        "appFile.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#atl</td>\n",
              "      <td>30</td>\n",
              "      <td>-7.705262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#atlanta</td>\n",
              "      <td>30</td>\n",
              "      <td>-7.705262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#bjcbranding</td>\n",
              "      <td>30</td>\n",
              "      <td>-7.705262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#buddypress</td>\n",
              "      <td>30</td>\n",
              "      <td>-7.705262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#career</td>\n",
              "      <td>30</td>\n",
              "      <td>-7.705262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           word  frequency  probability\n",
              "0          #atl         30    -7.705262\n",
              "1      #atlanta         30    -7.705262\n",
              "2  #bjcbranding         30    -7.705262\n",
              "3   #buddypress         30    -7.705262\n",
              "4       #career         30    -7.705262"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1Fbhjy7WBii"
      },
      "source": [
        "## Helper functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwGcIPt8WBij"
      },
      "source": [
        "I need a function gives me a word probability in any of the data frames that I used for the two classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-PKJ6uhWBik",
        "outputId": "65498537-8355-47a9-88b9-b1ee175e91a5"
      },
      "source": [
        "def get_w_prob(word, dataframe):\n",
        "    prob = dataframe[dataframe.word == word].probability\n",
        "    if len(prob) > 0:\n",
        "        return prob.values[0]\n",
        "    else:\n",
        "        return math.log(1/math.log(sum(dataframe.frequency)))\n",
        "    \n",
        "get_w_prob(\"#al\", appFile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-2.40752690809659"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9wDqSVVWBik"
      },
      "source": [
        "I also need to compute the prior probability of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4b7JC-fWBil",
        "outputId": "9205a8c4-e3fd-4e0e-b76c-5bf42396cef1"
      },
      "source": [
        "appPrior = math.log(len(appFile) / (len(appFile) + len(otherFile))) # Number of Tweets in app File / Total number of Tweets (sum of the number of tweets in both files)\n",
        "print(\"The prior of tweets belonging to the app is ={0:.2f}\\n\\n\".format(math.exp(appPrior)))\n",
        "\n",
        "otherPrior = math.log(len(otherFile) / (len(appFile) + len(otherFile))) # Number of Tweets in other File / Total number of Tweets (sum of the number of tweets in both files)\n",
        "print(\"The prior of tweets NOT belonging to the app is ={0:.2f}\".format(math.exp(otherPrior)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The prior of tweets belonging to the app is =0.48\n",
            "\n",
            "\n",
            "The prior of tweets NOT belonging to the app is =0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XxQoGBSWBil"
      },
      "source": [
        "### The Bayesian classifier. \n",
        "\n",
        "Let's build the classifier. I'm using a test set with a few tweets (`test.csv`), and the goal is to read them and say if they are about the APP or not. The test set is already labeled with the class each belongs to in the first column. We will loose that information to check if our prediction is OK.\n",
        "\n",
        "Read a test file, with the category label in V1 and the tweet contents in V2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7PlXscoWBim"
      },
      "source": [
        "test = pd.read_csv(\"data/test.csv\", header = None, names=[\"label\", \"content\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ApuyR0SWBim"
      },
      "source": [
        "Now, let's loop through the file to compute the MAP (maximum A Posterior Probability) and thus, determine which class the tweet belongs to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQO-dBz1WBim",
        "outputId": "31bda351-697d-409e-cf78-cb57ea0b158c"
      },
      "source": [
        "pred = []\n",
        "\n",
        "for j in range(0,len(test)):\n",
        "    tweet = test.iloc[j].content # Extract the content of the tweet\n",
        "    print(\"Processing tweet:\",tweet)\n",
        "    wordsInThisTweet = ' '.join(tweet.split()).strip().split(\" \") # Extract the words into a list\n",
        "    appProb = 0.0\n",
        "    otherProb = 0.0\n",
        "    \n",
        "    # For every word in this tweet, sum its frequency value.\n",
        "    for word in wordsInThisTweet:\n",
        "        appProb = appProb + get_w_prob(word, appFile)\n",
        "        otherProb = otherProb + get_w_prob(word, otherFile)\n",
        "  \n",
        "    posteriorAppPob = appProb * appPrior\n",
        "    posteriorOtherPob = otherProb * otherPrior\n",
        "    \n",
        "    # Categorize according to the score obtained from every subset (App tweets, and Other tweets)\n",
        "    if posteriorAppPob > posteriorOtherPob:\n",
        "        print(\"Prediction = {} | Actual Label= {}\".format(\"APP\", test.iloc[j].label))\n",
        "        print()\n",
        "        pred.append(\"APP\")\n",
        "    else:\n",
        "        print(\"Prediction = {} | Actual Label= {}\".format(\"OTHER\", test.iloc[j].label))\n",
        "        print()\n",
        "        pred.append(\"OTHER\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing tweet:  just love @mandrillapp transactional email service - http://mandrill.com sorry @sendgrid and @mailjet #timetomoveon\n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  @rossdeane mind submitting a request at http://help.mandrill.com with account details if you haven't already  glad to take a look \n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  @veroapp any chance you'll be adding mandrill support to vero \n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  @elie__ @camj59 jparle de relai smtp 1 million de mail chez mandrill / mois comparé à 1 million sur lite sendgrid y a pas photo avec mailjet\n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  would like to send emails for welcome  password resets  payment notifications  etc what should i use  was looking at mailgun/mandrill\n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  from coworker about using mandrill  \"i would entrust email handling to a pokemon\".\n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  @mandrill realised i did that about 5 seconds after hitting send \n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  holy shit it’s here http://www.mandrill.com/ \n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  our new subscriber profile page activity timeline  aggregate engagement stats  and mandrill integratio #bjcbranding http://bit.ly/13wau5c \n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  @mandrillapp increases scalability ( http://bit.ly/14myvuh  ) then decreases pricing ( http://bit.ly/13uja7s  ) #selfinducedcannibalization\n",
            "Prediction = APP | Actual Label= APP\n",
            "\n",
            "Processing tweet:  the beets  rt @missmya #nameanamazingband mandrill \n",
            "Prediction = OTHER | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  rt @luissand0val fernando vargas mandrill mexican pride mma\n",
            "Prediction = OTHER | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  photo oculi-ds mandrill by natalie manuel http://tmblr.co/zjqanxhdswlr \n",
            "Prediction = APP | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  @mandrill me neither    we can be :sadpanda together :(\n",
            "Prediction = APP | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  @mandrill n  / ( k  * ( n  - k  ) ) where n = 5 and k = 4  it has been a long time but i think that is it\n",
            "Prediction = OTHER | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  megaman x - spark mandrill acapella http://youtu.be/hyx9-kwyjdi  @youtubeさんから\n",
            "Prediction = OTHER | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  @angeluserrare1 storm eagle ftw     nomás no dejes que se le acerque spark mandrill xd\n",
            "Prediction = OTHER | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  gostei de um vídeo @youtube http://youtu.be/xzny7zimtni aspark … mandrill's stage on guitar (mega man x)\n",
            "Prediction = APP | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  what is 2-year-old mandrill  jj  thinking in this pic  http://ow.ly/jfrqf  re-tweet with your caption.\n",
            "Prediction = APP | Actual Label= OTHER\n",
            "\n",
            "Processing tweet:  120 years of moscow zoo - mandrill - поста ссср  #postage #stamp 3347 from soviet union in 1984 #philately http://tinyurl.com/cguyvzb \n",
            "Prediction = OTHER | Actual Label= OTHER\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2icPIq0WBin"
      },
      "source": [
        "Let's now print the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3orlvApwWBin",
        "outputId": "9367e170-47f2-47ea-991a-fdafafa9a91e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sn\n",
        "print(\"Accuracy = {}\".format(accuracy_score(test.label, pred)))\n",
        "print()\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "cm = confusion_matrix(test.label, pred)\n",
        "sn.heatmap(cm, annot=True, cmap=plt.cm.Blues);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8\n",
            "\n",
            "Confusion Matrix\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKSNtCtMWBip"
      },
      "source": [
        "An amazing 85% of Accuracy with this simple implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_25oi_3WBip"
      },
      "source": [
        "# Exercise #2 (FUNDAMENTAL)\n",
        "We are going to play now with another application of Naive Bayes: positive/negative prediction.\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "We will apply Naive Bayes to classify movie reviews according to their overall sentiment (positive/negative). In particular, we will use the Pang and Lee’s IMDB movie reviews data which contains 2000 reviews, each with a positive or negative sentiment label.\n",
        "\n",
        "I recommend you to take a look to the entry in the sklearn documentation devoted to working with textual representations: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA5Cr8MQWBiq"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "Read the IMDB dataset from the data folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYRedxEwWBiq"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npff_UCGWBir"
      },
      "source": [
        "In order to be able to manage the text documents, we first need to transform the text content into numerical feature vectors (i.e., vectorize).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3RXOTvNWBir"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUYfCfZnWBir"
      },
      "source": [
        "## Training and Test data sets.\n",
        "\n",
        "Separate data into training and test sets (80% for training and 20% for test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33E4po4XWBis"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUCHI9UCWBis"
      },
      "source": [
        "## Naïve Bayes Model\n",
        "\n",
        "Making use of the `naive_bayes` package (https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes), predict the polarity of the reviews in the test set and Calculate the confusion matrix and the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezXA8aMbWBit"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}